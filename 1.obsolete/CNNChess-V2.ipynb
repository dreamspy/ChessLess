{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compile\n",
      "summary\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_187 (Conv2D)          (None, 64, 1, 1)          4160      \n",
      "_________________________________________________________________\n",
      "flatten_63 (Flatten)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_63 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 4,225\n",
      "Trainable params: 4,225\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "loading blitzz\n",
      "done loading:  data/blitzz.data\n",
      "Epoch 1/10\n",
      "6475/6475 [==============================] - 2s 290us/step - loss: 161.3419 - acc: 0.0015\n",
      "Epoch 2/10\n",
      "6475/6475 [==============================] - 1s 83us/step - loss: 161.3419 - acc: 0.0015\n",
      "Epoch 3/10\n",
      "6475/6475 [==============================] - 0s 72us/step - loss: 161.3419 - acc: 0.0015\n",
      "Epoch 4/10\n",
      "6475/6475 [==============================] - 0s 75us/step - loss: 161.3419 - acc: 0.0015\n",
      "Epoch 5/10\n",
      "6475/6475 [==============================] - 0s 70us/step - loss: 161.3419 - acc: 0.0015\n",
      "Epoch 6/10\n",
      "6475/6475 [==============================] - 0s 70us/step - loss: 161.3419 - acc: 0.0015\n",
      "Epoch 7/10\n",
      "6475/6475 [==============================] - 0s 69us/step - loss: 161.3419 - acc: 0.0015\n",
      "Epoch 8/10\n",
      "6475/6475 [==============================] - 0s 76us/step - loss: 161.3419 - acc: 0.0015\n",
      "Epoch 9/10\n",
      "6475/6475 [==============================] - 0s 70us/step - loss: 161.3419 - acc: 0.0015\n",
      "Epoch 10/10\n",
      "6475/6475 [==============================] - 0s 70us/step - loss: 161.3419 - acc: 0.0015\n",
      "loading standar\n",
      "done loading:  data/standar.data\n",
      "evaluating\n",
      "score:  [122.44636039955499, 0.0018042680271262365]\n",
      "Done\n",
      "\n",
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "# 3. Import libraries and modules\n",
    "import numpy as np\n",
    "np.random.seed(123)  # for reproducibility\n",
    " \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "from keras.models import model_from_json\n",
    "\n",
    "pieceMapW = {\n",
    "  '1': 0,\n",
    "  'p': 1,\n",
    "  'r': 2,\n",
    "  'n': 3,\n",
    "  'b': 4,\n",
    "  'q': 5,\n",
    "  'k': 6,\n",
    "  'P': 7,\n",
    "  'R': 8,\n",
    "  'N': 9,\n",
    "  'B': 10,\n",
    "  'Q': 11,\n",
    "  'K': 12\n",
    "}\n",
    "\n",
    "pieceMapB = {\n",
    "  '1': 0,\n",
    "  'P': 1,\n",
    "  'R': 2,\n",
    "  'N': 3,\n",
    "  'B': 4,\n",
    "  'Q': 5,\n",
    "  'K': 6,\n",
    "  'p': 7,\n",
    "  'r': 8,\n",
    "  'n': 9,\n",
    "  'b': 10,\n",
    "  'q': 11,\n",
    "  'k': 12  \n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "def loadData(dataset,nRows):\n",
    "    X_vals = []\n",
    "    Y_vals = []\n",
    "    i = 0\n",
    "    pm = pieceMapW\n",
    "    with open(dataset,'r') as data:\n",
    "        boardLine = data.readline()\n",
    "\n",
    "        while boardLine and i < nRows:\n",
    "            boardData = boardLine.split(':')\n",
    "            boardR = boardData[0].split('/')\n",
    "            board = boardR[0:8]\n",
    "            board[7] = board[7][0:8]\n",
    "            who = boardR[7][9]\n",
    "            \n",
    "            if who == 'w':\n",
    "                nBoard = []\n",
    "                nLine = []\n",
    "                for line in board:\n",
    "                    for piece in line:\n",
    "                        nLine.append(pm[piece])\n",
    "                    nBoard.append(nLine)\n",
    "                    nLine = []\n",
    "\n",
    "                X_vals.append(nBoard)\n",
    "                #Y_vals.append(1 if float(boardData[2]) > 0 else 0)\n",
    "                pc = float(boardData[1])\n",
    "                Y_vals.append(pc)\n",
    "#                 print(boardLine)\n",
    "#                 print(nBoard)\n",
    "#                 print(pc,\"\\n\")\n",
    "            boardLine = data.readline()\n",
    "            i += 1\n",
    "        X_vals = np.array(X_vals)\n",
    "        Y_vals = np.array(Y_vals)\n",
    "#         print('wat',X_vals.shape)\n",
    "#         print('Y', Y_vals[4:10])\n",
    "        #Xraw = data.split('\\n').map(lambda r: r.split('/'))\n",
    "\n",
    "    # 4. Load pre-shuffled MNIST data into train and test sets\n",
    "\n",
    "#     split = nRows // 2\n",
    "#     (X_train, y_train) = X_vals[0:split], Y_vals[0: split].reshape(split,1)\n",
    "#     (X_test, y_test) = X_vals[split :], Y_vals[split :].reshape(split,1)\n",
    "    #(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n",
    "    #n = 6000\n",
    "    #X_train = X_train[0:n]\n",
    "    #y_train = y_train[0:n]\n",
    "    #X_test = X_test[0:n]\n",
    "    #y_test = y_test[0:n]\n",
    "\n",
    "    # 5. Preprocess input data\n",
    "    X_vals = X_vals.reshape(X_vals.shape[0], *chess_shape)\n",
    "    \n",
    "#     X_train = X_train.reshape(X_train.shape[0], *chess_shape)\n",
    "#     X_test = X_test.reshape(X_test.shape[0], *chess_shape)\n",
    "    \n",
    "    #X_train = X_train.astype('float32')\n",
    "    #X_test = X_test.astype('float32')\n",
    "    #X_train /= 12\n",
    "    #X_test /= 12\n",
    "\n",
    "\n",
    "    print(\"done loading: \", dataset)\n",
    "    return X_vals, Y_vals\n",
    "\n",
    "chess_shape = (1, 8, 8)\n",
    "\n",
    "\n",
    "# 7. Define model architecture\n",
    "model = Sequential()\n",
    "model.add(Dense(, input_dim=8, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "# model.add(Convolution2D(64, (8, 8), activation='tanh', input_shape=chess_shape, data_format='channels_first'))\n",
    "# model.add(Convolution2D(64, (3, 3), activation='relu', input_shape=chess_shape, data_format='channels_first'))\n",
    "# model.add(Dropout(0.25))\n",
    "# model.add(Convolution2D(96, (3, 3), activation='relu'))\n",
    "# model.add(Dropout(0.25))\n",
    "# model.add(Convolution2D(256, (3, 3), activation='relu'))\n",
    "# model.add(Dropout(0.25))\n",
    " \n",
    "model.add(Flatten())\n",
    "model.add(Dense(1, activation='softmax'))\n",
    "\n",
    "print('compile')\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "print('summary')\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n",
    "# X_train, Y_train = loadData('data/smallSample2.data',2)\n",
    "# model.fit(X_train, Y_train, batch_size=32, epochs=10, verbose=1)\n",
    "# score = model.evaluate(X_train[0:2], Y_train[0:2, verbose=0)\n",
    "# print(\"score: \",score)\n",
    "# print(X_train[0:2])\n",
    "# print(\"orginal data: \",Y_train[0:2])\n",
    "# print(model.predict(X_train[0:2]))\n",
    "\n",
    "# #Train\n",
    "print(\"loading blitzz\")\n",
    "X_train, Y_train = loadData('data/blitzz.data',13000)\n",
    "# # X_train, Y_train = loadData('data/blitzz.data',1300000)\n",
    "model.fit(X_train, Y_train, batch_size=32, epochs=10, verbose=1)\n",
    "\n",
    "print(\"loading standar\")\n",
    "X_test, Y_test = loadData('data/standar.data',64000)\n",
    "# X_test, Y_test = loadData('data/standar.data',640000)\n",
    "print(\"evaluating\")\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"score: \",score)\n",
    "# print(Y_test[0:10])\n",
    "# print(model.predict(Y_test[0:10]))\n",
    "# print(\"loading lightning\")\n",
    "# X_train, Y_train = loadData('data/lightning.data',890000)\n",
    "# model.fit(X_train, Y_train, batch_size=32, epochs=10, verbose=1)\n",
    "\n",
    "# print(\"evaluating\")\n",
    "# score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "# print(\"score: \",score)\n",
    "\n",
    "# print(\"loading titled\")\n",
    "# X_train, Y_train = loadData('data/titled.data',3200000)\n",
    "# # 10. Evaluate model on test data\n",
    "\n",
    "# print(\"evaluating\")\n",
    "# score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "# print(\"score: \",score)\n",
    "\n",
    "print(\"Done\\n\")\n",
    "\n",
    "# serialize model to JSON\n",
    "model_json = model.to_json()\n",
    "with open(\"model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "# serialize weights to HDF5\n",
    "model.save_weights(\"model.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "# load json and create model\n",
    "# json_file = open('model.json', 'r')\n",
    "# loaded_model_json = json_file.read()\n",
    "# json_file.close()\n",
    "# loaded_model = model_from_json(loaded_model_json)\n",
    "# # load weights into new model\n",
    "# loaded_model.load_weights(\"model.h5\")\n",
    "# print(\"Loaded model from disk\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.99  1.99  1.99  1.99  1.99  1.99  1.99  1.99  1.99  1.99  1.99  1.99\n",
      "  1.99  1.99  1.99  1.99  1.99  1.99  1.99  1.99]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.],\n",
       "       [ 1.]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(Y_train)\n",
    "model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 1s 38us/step\n",
      "score is [0.8661627592849731, 0.24479999999999999]\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
