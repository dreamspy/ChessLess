{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wat (1000000, 773)\n",
      "Y [-0.02  0.1  -0.42  7.38  0.27  0.86]\n",
      "(750000, 773)\n",
      "[0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[[-0.25]\n",
      " [ 2.76]\n",
      " [-0.98]\n",
      " ..., \n",
      " [-1.18]\n",
      " [ 0.87]\n",
      " [ 0.25]]\n",
      "(750000, 773) (750000, 1)\n",
      "(250000, 773) (250000, 1)\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "# 3. Import libraries and modules\n",
    "import numpy as np\n",
    "np.random.seed(123)  # for reproducibility\n",
    " \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.datasets import mnist\n",
    "\n",
    "pieceMap = {\n",
    "  '1': [0,0,0,0,0,0,0,0,0,0,0,0],\n",
    "  'p': [0,0,0,0,0,0,0,0,0,0,0,1],\n",
    "  'r': [0,0,0,0,0,0,0,0,0,0,1,0],\n",
    "  'n': [0,0,0,0,0,0,0,0,0,1,0,0],\n",
    "  'b': [0,0,0,0,0,0,0,0,1,0,0,0],\n",
    "  'q': [0,0,0,0,0,0,0,1,0,0,0,0],\n",
    "  'k': [0,0,0,0,0,0,1,0,0,0,0,0],\n",
    "  'P': [0,0,0,0,0,1,0,0,0,0,0,0],\n",
    "  'R': [0,0,0,0,1,0,0,0,0,0,0,0],\n",
    "  'N': [0,0,0,1,0,0,0,0,0,0,0,1],\n",
    "  'B': [0,0,1,0,0,0,0,0,0,0,0,1],\n",
    "  'Q': [0,1,0,0,0,0,0,0,0,0,0,1],\n",
    "  'K': [1,0,0,0,0,0,0,0,0,0,0,1]\n",
    "}\n",
    "\n",
    "X_vals = []\n",
    "Y_vals = []\n",
    "\n",
    "i, nRows = 0, 1000000\n",
    "input_neurons = 773\n",
    "#data_shape = (nRows, input_neurons)\n",
    "castlingAssert = 0\n",
    "with open('allData.shuffled.data','r') as data:\n",
    "    boardLine = data.readline()\n",
    "    \n",
    "    while boardLine and i < nRows:\n",
    "        boardData = boardLine.split(':')\n",
    "        boardR = boardData[0].split('/')\n",
    "        board = boardR[0:8]\n",
    "        \n",
    "        board[7] = board[7][0:8]\n",
    "        \n",
    "        score = float(boardData[1])\n",
    "        \n",
    "        \n",
    "                \n",
    "        # Append 12x 0-1 neurons for each of 8 positions in each line\n",
    "        nBoard = []\n",
    "        for line in board:\n",
    "            for piece in line:\n",
    "                nBoard.extend(pieceMap[piece])\n",
    "        \n",
    "        # Append 0-1 neuron for current player\n",
    "        who = boardR[7][9]\n",
    "        assert who == 'w' or who == 'b', 'line {0}: expected position 9 to be current player'.format(i)\n",
    "        nBoard.append(0 if who == 'w' else 1)\n",
    "        \n",
    "        # Append 4x 0-1 neurons for castling\n",
    "        castlingRaw = boardR[7][11:15]\n",
    "        \n",
    "        #print(i, castlingRaw)\n",
    "        \n",
    "        castling = list(filter(lambda c: c in ['-', 'K', 'k', 'Q','q'], castlingRaw))\n",
    "        #print(i, castling)\n",
    "        \n",
    "        assert len(castling) > 0, 'line {0}: expected castling {1} to be some characters'.format(i, castling)\n",
    "        \n",
    "        if len(castling) < 4: castlingAssert += 1\n",
    "        #assert all(c in ['-', 'K', 'k', 'Q','q', ' '] for c in castling), 'line {0}: expected {1} to be castling rights'.format(i, castling)\n",
    "        nBoard.append(1 if 'k' in castling else 0)\n",
    "        nBoard.append(1 if 'q' in castling else 0)\n",
    "        nBoard.append(1 if 'K' in castling else 0)\n",
    "        nBoard.append(1 if 'Q' in castling else 0)\n",
    "        \n",
    "        assert len(nBoard) == input_neurons, 'line {0}: expected {2} neurons per board, got {1}'.format(i, len(nBoard), input_neurons)\n",
    "        \n",
    "        X_vals.append(nBoard)\n",
    "        #Y_vals.append(1 if float(boardData[2]) > 0 else 0)\n",
    "#         print(boardData)\n",
    "        Y_vals.append(float(boardData[1]))\n",
    "        boardLine = data.readline()\n",
    "        i += 1\n",
    "    X_vals = np.array(X_vals)\n",
    "    Y_vals = np.array(Y_vals)\n",
    "    print('wat',X_vals.shape)\n",
    "    print('Y', Y_vals[4:10])\n",
    "    #Xraw = data.split('\\n').map(lambda r: r.split('/'))\n",
    "    #print(Xraw.shape)\n",
    "    \n",
    "# sanity check for if input makes sense ... since a small number of lines have 2 instead of 4 characters for castling rights\n",
    "#assert castlingAssert / nRows < 0.2, 'expected most of the rows to have 4 character castling rights {0}'.format(castlingAssert / nRows)\n",
    "\n",
    "# 4. Load pre-shuffled MNIST data into train and test sets\n",
    "\n",
    "split = nRows // 4\n",
    "(X_train, y_train) = X_vals[0:3*split], Y_vals[0: 3*split].reshape(3*split,1)\n",
    "(X_test, y_test) = X_vals[3*split :], Y_vals[3*split :].reshape(split,1)\n",
    "#(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print(X_train.shape)\n",
    "\n",
    "print(X_train[0])\n",
    "\n",
    "#n = 6000\n",
    "#X_train = X_train[0:n]\n",
    "#y_train = y_train[0:n]\n",
    "#X_test = X_test[0:n]\n",
    "#y_test = y_test[0:n]\n",
    "\n",
    "# 5. Preprocess input data\n",
    "X_train = X_train.reshape(X_train.shape[0], input_neurons)\n",
    "X_test = X_test.reshape(X_test.shape[0], input_neurons)\n",
    "#X_train = X_train.astype('float32')\n",
    "#X_test = X_test.astype('float32')\n",
    "#X_train /= 12\n",
    "#X_test /= 12\n",
    "\n",
    "print(y_train)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)\n",
    " \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -0.25]\n",
      " [  2.76]\n",
      " [ -0.98]\n",
      " [  1.72]\n",
      " [ -0.02]\n",
      " [  0.1 ]\n",
      " [ -0.42]\n",
      " [  7.38]\n",
      " [  0.27]\n",
      " [  0.86]\n",
      " [ -0.6 ]\n",
      " [ 13.13]\n",
      " [  0.77]\n",
      " [ -0.08]\n",
      " [  4.08]\n",
      " [  0.81]\n",
      " [ -0.36]\n",
      " [  0.98]\n",
      " [  0.42]\n",
      " [  0.35]]\n",
      "[ 500.]\n",
      "[-400.]\n",
      "[[ -0.25]\n",
      " [  2.76]\n",
      " [ -0.98]\n",
      " [  1.72]\n",
      " [ -0.02]\n",
      " [  0.1 ]\n",
      " [ -0.42]\n",
      " [  7.38]\n",
      " [  0.27]\n",
      " [  0.86]\n",
      " [ -0.6 ]\n",
      " [ 13.13]\n",
      " [  0.77]\n",
      " [ -0.08]\n",
      " [  4.08]\n",
      " [  0.81]\n",
      " [ -0.36]\n",
      " [  0.98]\n",
      " [  0.42]\n",
      " [  0.35]]\n",
      "[ 400.]\n",
      "[-300.]\n",
      "compile\n",
      "summary\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_27 (Dense)             (None, 600)               464400    \n",
      "_________________________________________________________________\n",
      "dense_28 (Dense)             (None, 400)               240400    \n",
      "_________________________________________________________________\n",
      "dense_29 (Dense)             (None, 200)               80200     \n",
      "_________________________________________________________________\n",
      "dense_30 (Dense)             (None, 100)               20100     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_31 (Dense)             (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 805,201\n",
      "Trainable params: 805,201\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "(750000, 773) (750000, 1)\n",
      "Epoch 1/10\n",
      "750000/750000 [==============================] - 223s 297us/step - loss: 108.8006 - acc: 0.0119\n",
      "Epoch 2/10\n",
      "750000/750000 [==============================] - 218s 291us/step - loss: 102.9741 - acc: 0.0100\n",
      "Epoch 3/10\n",
      "750000/750000 [==============================] - 214s 285us/step - loss: 96.5755 - acc: 0.0101\n",
      "Epoch 4/10\n",
      "750000/750000 [==============================] - 213s 284us/step - loss: 89.6664 - acc: 0.0096\n",
      "Epoch 5/10\n",
      "750000/750000 [==============================] - 212s 283us/step - loss: 81.8596 - acc: 0.0093\n",
      "Epoch 6/10\n",
      "750000/750000 [==============================] - 212s 283us/step - loss: 74.2214 - acc: 0.0085\n",
      "Epoch 7/10\n",
      "750000/750000 [==============================] - 216s 287us/step - loss: 66.8455 - acc: 0.0097\n",
      "Epoch 8/10\n",
      "750000/750000 [==============================] - 213s 283us/step - loss: 60.6701 - acc: 0.0099\n",
      "Epoch 9/10\n",
      "750000/750000 [==============================] - 215s 286us/step - loss: 55.1946 - acc: 0.0121\n",
      "Epoch 10/10\n",
      "750000/750000 [==============================] - 212s 283us/step - loss: 51.2921 - acc: 0.0109\n",
      "score:  [120.17468444767761, 0.011996]\n"
     ]
    }
   ],
   "source": [
    "# 6. Preprocess class labels\n",
    "print(y_train[0:20])\n",
    "print(max(y_train))\n",
    "print(min(y_train))\n",
    "\n",
    "#Y_train = np_utils.normalize(y_train)\n",
    "#Y_test = np_utils.normalize(y_test)\n",
    "print(Y_train[0:20])\n",
    "print(max(Y_train))\n",
    "print(min(Y_train))\n",
    "\n",
    "Y_train = y_train\n",
    "Y_test = y_test\n",
    "#Y_train = np_utils.to_categorical(y_train, 2)\n",
    "#Y_test = np_utils.to_categorical(y_test, 2)\n",
    " \n",
    "# 7. Define model architecture\n",
    "model = Sequential()\n",
    " \n",
    "# model.add(Convolution2D(32, (3, 3), activation='relu', input_shape=(1,28,28)))\n",
    "model.add(Dense(600, activation='relu', input_shape=[input_neurons]))\n",
    "model.add(Dense(400, activation='relu'))\n",
    "model.add(Dense(200, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#model.add(Flatten())\n",
    "model.add(Dense(1, activation='linear'))\n",
    "#model.compile(loss='categorical_crossentropy',\n",
    "#              optimizer='adam',\n",
    "#              metrics=['accuracy'])\n",
    "\n",
    "print('compile')\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "print('summary')\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# 9. Fit model on training data\n",
    "print(X_train.shape, Y_train.shape)\n",
    "model.fit(X_train, Y_train, \n",
    "          batch_size=100, epochs=10, verbose=1)\n",
    "\n",
    "# 10. Evaluate model on test data\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "print(\"score: \",score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected dense_27_input to have shape (None, 773) but got array with shape (773, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-5d574497dc31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m  \u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m  \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m  0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))\n\u001b[0m",
      "\u001b[0;32m~/.virtualenvs/DATA/lib/python3.5/site-packages/keras/models.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose)\u001b[0m\n\u001b[1;32m    937\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    938\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 939\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    941\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/DATA/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1728\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[1;32m   1729\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1730\u001b[0;31m                                     check_batch_axis=False)\n\u001b[0m\u001b[1;32m   1731\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1732\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/DATA/lib/python3.5/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    152\u001b[0m                             \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m                             \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m                             str(array.shape))\n\u001b[0m\u001b[1;32m    155\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0marrays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking : expected dense_27_input to have shape (None, 773) but got array with shape (773, 1)"
     ]
    }
   ],
   "source": [
    "model.predict(np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
    " 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
    " 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    " 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
    " 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    " 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    " 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
    " 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    " 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    " 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    " 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    " 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    " 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    " 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
    " 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
    " 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    " 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
    " 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
    " 0 ,0 ,0 ,0 ,0 ,0 ,0 ,0 ,0 ,0 ,1 ,0 ,0 ,0 ,0 ,0 ,0 ,0 ,0 ,0 ,0 ,0 ,0 ,0 ,0 ,0 ,0 ,0 ,0 ,0 ,0 ,0 ,1 ,0 ,0 ,0 ,0,\n",
    " 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
    " 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
